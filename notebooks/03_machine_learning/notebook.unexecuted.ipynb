{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An introduction to machine learning using MLJ and the Titanic\n",
    "dataset. Explains how to train a simple decision tree model and\n",
    "evaluate it's performance on a holdout set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLJ is a *multi-paradigm* machine learning toolbox (i.e., not just\n",
    "deep-learning)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For other MLJ learning resources see the [Learning\n",
    "MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/learning_mlj/)\n",
    "section of the\n",
    "[manual](https://alan-turing-institute.github.io/MLJ.jl/dev/)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activate package environment"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(joinpath(@__DIR__, \"..\", \"..\"))\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Establishing correct data representation"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "import DataFrames"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A [\"scientific\n",
    "type\"](https://juliaai.github.io/ScientificTypes.jl/dev/) or\n",
    "*scitype* indicates how MLJ will *interpret* data (as opposed to how\n",
    "it is represented on your machine). For example, while we have"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "typeof(3.14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we have"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(3.14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and also"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(3.143f0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ, model data requirements are articulated using scitypes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are common \"scalar\" scitypes:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "html\"\"\"\n",
    "<div style=\"text-align: left\";>\n",
    "        <img src=\"https://github.com/ablaom/MLJTutorial.jl/blob/dev/notebooks/01_data_representation/scitypes.png?raw=true\">\n",
    "</div>\n",
    "\"\"\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are also container scitypes. For example, the scitype of any\n",
    "vector is `AbstractVector{S}`, where `S` is the scitype of its\n",
    "elements:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype([\"cat\", \"mouse\", \"dog\"])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll be using [OpenML](https://www.openml.org/home) to grab the\n",
    "Titanic dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "table = OpenML.load(42638)\n",
    "df0 = DataFrames.DataFrame(table)\n",
    "DataFrames.describe(df0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `schema` operator summarizes the column scitypes of a table:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(df0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like we need to fix `:sibsp`, the number of siblings/spouses:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df1 = coerce(df0, :sibsp => Count)\n",
    "schema(df1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets take a closer look at our target column :survived. Here a value\n",
    "`0` means that the individual didn't survive while a value of `1` indicates\n",
    "an individual survived."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "levels(df1.survived)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `:cabin` feature has a lot of missing values, and low frequency\n",
    "for other classes:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import StatsBase\n",
    "StatsBase.countmap(df0.cabin)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll make `missing` into a bona fide class and group all the other\n",
    "classes into one:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function class(c)\n",
    "    if ismissing(c)\n",
    "        return \"without cabin\"\n",
    "    else\n",
    "        return \"has cabin\"\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shorthand syntax would be `class(c) = ismissing(c) ? \"without cabin\" :\n",
    "\"has cabin\"`. Now to transform the whole column:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df2 = DataFrames.transform(\n",
    "    df1,\n",
    "    :cabin => DataFrames.ByRow(class) => :cabin\n",
    ") # :cabin now has `Textual` scitype\n",
    "coerce!(df2, :class => Multiclass)\n",
    "schema(df2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into train and test sets\n",
    "Here we split off 30% of our observations into a\n",
    "lock-and-throw-away-the-key holdout set, called `df_test`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df, df_test = partition(df2, 0.7, rng=123)\n",
    "DataFrames.nrow(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "DataFrames.nrow(df_test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's construct an MLJ model to impute missing data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cleaner = FillImputer()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a *model* is just a container for hyper-parameters associated with some ML\n",
    "algorithm. It does not store learned parameters (unlike scikit-learn \"estimators\"). In\n",
    "this case the hyper-parameters `features`, `continuous_fill`, `count_fill`, and\n",
    "`finite_fill` specify which features should be imputed and how imputation should be\n",
    "carried out, depending on the scitype. Since we didn't specify any features in our\n",
    "constructor, we are using default values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now bind the model with training data in a *machine*:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "machc = machine(cleaner, df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And train the machine to store learned parameters there (the column\n",
    "modes and medians to be used to impute missings):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(machc);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can inspect the learned parameters if we want:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(machc).filler_given_feature"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we apply the learned transformation on our data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dfc     =  transform(machc, df)\n",
    "dfc_test = transform(machc, df_test)\n",
    "schema(dfc)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data into input features and target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following method puts the column with name equal to `:survived`\n",
    "into the vector `y`, and everything else into a table (`DataFrame`)\n",
    "called `X`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(dfc, ==(:survived));\n",
    "scitype(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we're here, we'll do the same for the holdout test set:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y_test, X_test = unpack(dfc_test, ==(:survived));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing a supervised model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are not many models that can directly handle a mixture of\n",
    "scitypes, as we have here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(matching(X, y))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This can be mitigated with further pre-processing (such as one-hot\n",
    "encoding) but we'll settle for one the above models here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "doc(\"DecisionTreeClassifier\", pkg=\"BetaML\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Tree = @load DecisionTreeClassifier pkg=BetaML  # model type\n",
    "tree = Tree()                                   # default instance"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that by calling `Tree` with no arguments we get default\n",
    "values for the various hyperparameters that control how the tree is\n",
    "trained. We specify keyword arguments to overide these defaults. For example:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "small_tree = Tree(max_depth=3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A decision tree is frequently not the best performing model, but it\n",
    "is easy to interpret (and the algorithm is relatively easy to\n",
    "explain). For example, here's an diagramatic representation of a\n",
    "tree trained on (some part of) the Titanic data set, which suggests\n",
    "how prediction works:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "html\"\"\"\n",
    "<div style=\"text-align: left\";>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/5/58/Decision_Tree_-_survival_of_passengers_on_the_Titanic.jpg\">\n",
    "</div>\n",
    "\"\"\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The fit/predict worflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now the bind data to be used for training and evaluation to the model (ie, choice of\n",
    "hyperparameters) in a machine, just like we did for missing value imputation. In this\n",
    "case, however, we also need to specify the training target `y`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "macht = machine(tree, X, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To train using *all* the bound data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(macht)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And get predictions on the holdout set:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = predict(macht, X_test);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are *probabilistic* predictions:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p[3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pdf(p[3], \"0\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also get \"point\" predictions:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "yhat = mode.(p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can evaluate performance using a probabilistic measure, as in"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "log_loss(p, y_test) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or using a deterministic measure:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "accuracy(yhat, y_test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "List all performance measures with `measures()`. Naturally, MLJ\n",
    "includes functions to automate this kind of performance evaluation,\n",
    "but this is beyond the scope of this tutorial. See, eg,\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Getting-Started)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning more"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some suggestions for next steps are\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Getting-Started)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
